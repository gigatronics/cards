{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8025b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ginazhou/Documents/GitHub/cards\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['prod transfer cbi fct f24.json',\n",
       " 'student.json',\n",
       " 'sbx points.json',\n",
       " 'welcome.json',\n",
       " 'aero fx.json',\n",
       " 'unique ac bistro.json',\n",
       " 'aero 40 yr engagement.json',\n",
       " 'f25 winter btv.json',\n",
       " 'aero mobile wallet.json',\n",
       " 'mbna estmt.json',\n",
       " 'unique ac target.json',\n",
       " 'aero 40 yr acquisition.json',\n",
       " 'mbna spend stim.json',\n",
       " 'f25 winter aero.json',\n",
       " 'n2c.json',\n",
       " 'amazon grocery spend stim.json',\n",
       " 'aero 10 yr contest.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'config')\n",
    "fs = [f for f in os.listdir(path) if 'json' in f]\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76600cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "297d5b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign', 'pmdef '], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tmp_pmdef_cnt.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e25daca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'campaign': 'student', 'pmdef ': 3},\n",
       " {'campaign': 'mbna estmt', 'pmdef ': 6},\n",
       " {'campaign': 'n2c', 'pmdef ': 1}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = ['student', 'n2c', 'mbna estmt']\n",
    "df.loc[df['campaign'].isin(list)].to_dict(orient='records') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacafa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_jaccard(new_json, old_jsons,n) -> list:\n",
    "\n",
    "    def jaccard(json1, json2) -> float:\n",
    "        # get key & values\n",
    "        set1 = {key for key, value in json1.items() if value is True}\n",
    "        set2 = {key for key, value in json2.items() if value is True}\n",
    "        \n",
    "        # calc intersection and union\n",
    "        intersection = set1.intersection(set2)\n",
    "        union = set1.union(set2)\n",
    "        \n",
    "        # calc jccard similarity \n",
    "        if not union:  # Avoid division by zero\n",
    "            return 0.0\n",
    "        return len(intersection) / len(union)\n",
    "\n",
    "    # repeat for every json\n",
    "    scored_jsons = [(old_json['title'], jaccard(new_json, old_json)) for old_json in old_jsons]\n",
    "    # sort in descending order  \n",
    "    scored_jsons.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Return the top N similar JSONs with their scores\n",
    "    scored_jsons = [{\"title\": old_json['title'], \"score\": jaccard(new_json, old_json)} for old_json in old_jsons]\n",
    "    # sort a list of json, descending\n",
    "    sorted_jsons = sorted(scored_jsons, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    \n",
    "    # Return the top N similar JSONs with their scores  \n",
    "    return sorted_jsons[:n]     #scored_jsons[:n]\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d538342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Aeroplan FX Offer', 'score': 0.25},\n",
       " {'title': 'prod transfer - Cash Back Visa Infinite* & First Class Travel® Visa Infinite* Offers',\n",
       "  'score': 0.0},\n",
       " {'title': 'Cash Back Visa - Student Offer', 'score': 0.0}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "new_json = json.load(open(path+'/'+'bluejays.json', 'r')) \n",
    "old_jsons = [json.load(open(path+'/'+f, 'r')) for f in fs] \n",
    "\n",
    "# top 3 similar offer are - jaccard: \n",
    "top3 = calc_jaccard(new_json, old_jsons, 3)\n",
    "\n",
    "#print(f\"the top 3 matches are: \")\n",
    "#for idx, (json_obj, score) in enumerate(top3, start=1):\n",
    "#    print(f\"{idx}. {json_obj['title']}, w/ a similarity score of {score:.2f}\")\n",
    "\n",
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05adf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hamming(new_json, old_jsons,n):\n",
    "\n",
    "    def hamming(json1, json2):\n",
    "        # get key & values\n",
    "        set1 = {key for key, value in json1.items() if value is True}\n",
    "        set2 = {key for key, value in json2.items() if value is True}\n",
    "        \n",
    "        # calc intersection and union\n",
    "        keys = set1.union(set2)\n",
    "        \n",
    "        # Calculate Hamming distance\n",
    "        hamming = sum(json1.get(key, False) != json2.get(key, False) for key in keys)\n",
    "        \n",
    "        total_keys = len(keys)\n",
    "        return 1 - (hamming / total_keys)\n",
    "\n",
    "    # repeat for every json\n",
    "    scored_jsons = [(old_json, hamming(new_json, old_json)) for old_json in old_jsons]\n",
    "\n",
    "    # sort in descending order  \n",
    "    scored_jsons.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the top N similar JSONs with their scores\n",
    "    return scored_jsons[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daada57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'title': 'Aeroplan FX Offer',\n",
       "   'is_contest': False,\n",
       "   'is_tiered_offer': False,\n",
       "   'is_mobile_wallet_related': False,\n",
       "   'has_annual_fee': False,\n",
       "   'requires_physical_location': False,\n",
       "   'includes_amazon_cards': False,\n",
       "   'includes_aero_cards': True,\n",
       "   'is_location_based_promotion': True,\n",
       "   'points_or_cashback_or_both': 'points',\n",
       "   'consumer_or_business_or_both': 'consumer',\n",
       "   'payout_structure': 'one-off',\n",
       "   'campaign_duration': 'months',\n",
       "   'requires_opt_in': True,\n",
       "   'external_partners': ['Air Canada'],\n",
       "   'distribution_channel': 'launched within cards',\n",
       "   'qualification_transaction_count': 'single',\n",
       "   'qualification_basis': 'amount spend',\n",
       "   'single_or_multiple_products': 'single',\n",
       "   'td_or_mbna_products': 'TD',\n",
       "   'td_rewards_or_aero_or_both': 'aero',\n",
       "   'new_accounts_or_transfers_or_both': 'existing accounts'},\n",
       "  0.25),\n",
       " ({'title': 'TD Cash Back Visa Infinite* and TD First Class Travel® Visa Infinite* Offers',\n",
       "   'is_contest': False,\n",
       "   'is_tiered_offer': True,\n",
       "   'is_mobile_wallet_related': False,\n",
       "   'has_annual_fee': True,\n",
       "   'requires_physical_location': False,\n",
       "   'includes_amazon_cards': False,\n",
       "   'includes_aeroplan_cards': False,\n",
       "   'is_location_based_promotion': False,\n",
       "   'points_or_cashback_or_both': 'both',\n",
       "   'consumer_or_business_or_both': 'consumer',\n",
       "   'payout_structure': 'multi-part',\n",
       "   'campaign_duration': 'November 18, 2024 – January 6, 2025',\n",
       "   'requires_opt_in': False,\n",
       "   'external_partners': ['Expedia For TD'],\n",
       "   'distribution_channel': 'public offer',\n",
       "   'qualification_transaction_count': 'multiple',\n",
       "   'qualification_basis': 'spend-based and first purchase',\n",
       "   'single_or_multiple_products': 'multiple',\n",
       "   'td_or_mbna_products': 'TD',\n",
       "   'td_rewards_or_aero_or_both': 'TD Rewards',\n",
       "   'new_accounts_or_transfers_or_both': 'new accounts',\n",
       "   'requires_paperless_opt_in': False},\n",
       "  0.0),\n",
       " ({'title': 'Cash Back Visa - Student Offer',\n",
       "   'is_contest': False,\n",
       "   'is_tiered_offer': False,\n",
       "   'is_mobile_wallet_related': True,\n",
       "   'has_annual_fee': False,\n",
       "   'requires_physical_location': False,\n",
       "   'includes_amazon_cards': False,\n",
       "   'includes_aeroplan_cards': False,\n",
       "   'is_location_based_promotion': False,\n",
       "   'points_or_cashback_or_both': 'cashback',\n",
       "   'consumer_or_business_or_both': 'consumer',\n",
       "   'payout_structure': 'one-time payout',\n",
       "   'campaign_duration': 'November 1, 2024 – April 30, 2025',\n",
       "   'requires_opt_in': True,\n",
       "   'external_partners': ['Apple Pay', 'Google Pay', 'Samsung Pay'],\n",
       "   'distribution_channel': 'student-specific offer',\n",
       "   'qualification_transaction_count': 'multiple',\n",
       "   'qualification_basis': 'mobile purchases and spending',\n",
       "   'single_or_multiple_products': 'single',\n",
       "   'td_or_mbna_products': 'TD',\n",
       "   'td_rewards_or_aero_or_both': 'Cash Back',\n",
       "   'new_accounts_or_transfers_or_both': 'new accounts',\n",
       "   'requires_paperless_opt_in': False},\n",
       "  0.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# try hamming \n",
    "top3 = calc_hamming(new_json, old_jsons, 10)\n",
    "print(f\"\")\n",
    "print(f\"the top 3 campaigns matching {fs[1]} are: \")\n",
    "for idx, (json_obj, score) in enumerate(top3, start=1):\n",
    "    print(f\"{idx}. {json_obj['title']} with a score of {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4192a142",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import DictVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import mean\n",
    "\n",
    "def calc_cosine(new_json, old_jsons, n):\n",
    "    all_jsons = old_jsons + [new_json]\n",
    "    \n",
    "    # vectorize json \n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    feature_vectors = vectorizer.fit_transform(all_jsons)\n",
    "    \n",
    "    # calc consine similarity\n",
    "    new_vector = feature_vectors[-1].reshape(1, -1)   \n",
    "    old_vectors = feature_vectors[:-1]   \n",
    "\n",
    "    score = cosine_similarity(new_vector, old_vectors).flatten()\n",
    "    avg = mean(scores)\n",
    "    \n",
    "    return scores.tolist(), avg\n",
    "\n",
    "scores, avg_score = calculate_similarity_score(new_json, old_jsons)\n",
    "\n",
    "print(\"Similarity Scores:\", scores)\n",
    "print(\"Average Similarity Score:\", avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b2270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0ba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da57ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2113981774.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    'aero rec & enter tiered': 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#example \n",
    "\n",
    "risk_scores = [\n",
    "    {'id': 1, 'score': 50, 'reasons': ['Age below 25', 'Income below $30,000']},\n",
    "    {'id': 2, 'score': 30, 'reasons': ['Good credit history']}\n",
    "]\n",
    "\n",
    "\n",
    "pmdef_count = { 'aero mobile wallet tiered': 5 \n",
    "                'aero rec & enter tiered': 1\n",
    "                'aero fx': 11 \n",
    "                'aero rando': 4\n",
    "                'new campaign': \"\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fd042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
